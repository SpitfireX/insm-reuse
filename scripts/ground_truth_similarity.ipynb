{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import sqlite3\n",
    "import json\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from copy import deepcopy\n",
    "\n",
    "import ngram_similarity\n",
    "import modified_ngram_similarity\n",
    "\n",
    "from own_infer import chunk"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "con = sqlite3.connect(\"meter3.db\")\n",
    "cur = con.cursor()\n",
    "\n",
    "ngs = ngram_similarity.NgramSimilarity(\"en\")\n",
    "mngs = modified_ngram_similarity.ModifiedNgramSimilarity(\"en\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# import cProfile\n",
    "# import time\n",
    "\n",
    "# def dostuff():\n",
    "\n",
    "#     sql_extra_gt = \"\"\"\n",
    "#     select\n",
    "#         t1.id as ida, t2.id as idb\n",
    "#     from extra as t1\n",
    "#         cross join extra as t2\n",
    "#     where\n",
    "#         t1.id <> t2.id\n",
    "#     \"\"\"\n",
    "\n",
    "#     def nth(it, n):\n",
    "#         for i, e in enumerate(it):\n",
    "#             if i % n == 0:\n",
    "#                 yield e\n",
    "\n",
    "#     nrows = cur.execute(\"select count(*) from extra as t1 cross join extra as t2 where t1.id <> t2.id\").fetchone()[0]\n",
    "\n",
    "#     n = 0\n",
    "\n",
    "#     for ida, idb in nth(cur.execute(sql_extra_gt).fetchall(), int(nrows/2000)):\n",
    "\n",
    "#         texta = cur.execute(f\"select text from extra where id={ida}\").fetchone()[0]\n",
    "#         textb = cur.execute(f\"select text from extra where id={idb}\").fetchone()[0]\n",
    "        \n",
    "#         if len(texta) > 50_000 or len(textb) > 50_000:\n",
    "#             continue\n",
    "        \n",
    "#         st = time.time()\n",
    "\n",
    "#         scores = ngs.score_texts(texta, textb)\n",
    "#         mscores = mngs.score_texts(texta, textb, ngram_length=5)\n",
    "\n",
    "#         print(time.time() - st)\n",
    "\n",
    "#         if n < 10:\n",
    "#             n += 1\n",
    "#         else:\n",
    "#             break\n",
    "\n",
    "# cProfile.run('dostuff()', 'meter.profile')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def init_worker(ngs_scorer, mngs_scorer):\n",
    "    global w_ngs_scorer\n",
    "    global w_mngs_scorer\n",
    "    w_ngs_scorer = ngs_scorer\n",
    "    w_mngs_scorer = mngs_scorer\n",
    "\n",
    "def score_rows(rows):\n",
    "    return {(sid, tid): {**w_ngs_scorer.score_texts(a, b), **w_mngs_scorer.score_texts(a, b)} for sid, tid, a, b in rows}\n",
    "\n",
    "def get_meter_rows():\n",
    "    for sid, catch, src in cur.execute(\"SELECT id, catchline, text FROM sources\").fetchall():\n",
    "        for tid, text in cur.execute(\"SELECT id, text FROM texts WHERE catchline='{}'\".format(catch)).fetchall():\n",
    "            yield (sid, tid, src, text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# raise KeyboardInterrupt\n",
    "\n",
    "with ProcessPoolExecutor(max_workers = 24, initializer = init_worker, initargs = (ngram_similarity.NgramSimilarity(\"en\"), modified_ngram_similarity.ModifiedNgramSimilarity(\"en\"))) as executor:\n",
    "    for batch in chunk(24, chunk(50, get_meter_rows())):\n",
    "        jobs = []\n",
    "\n",
    "        for workbundle in batch:\n",
    "            job = executor.submit(score_rows, workbundle)\n",
    "            jobs.append(job)\n",
    "        \n",
    "        bundleresults = [f.result() for f in as_completed(jobs)]\n",
    "        for results in bundleresults:\n",
    "            for (sid, tid), scores in results.items():\n",
    "                cur.execute(\n",
    "                    \"INSERT OR IGNORE INTO predictions VALUES (?, ?, ?, ?)\",\n",
    "                    (\n",
    "                        sid,\n",
    "                        tid,\n",
    "                        json.dumps(scores, ensure_ascii=False),\n",
    "                        None\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        con.commit()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# # raise KeyboardInterrupt\n",
    "\n",
    "# sql_extra_gt = \"\"\"\n",
    "# select\n",
    "#     t1.id as ida, t2.id as idb\n",
    "# from extra as t1\n",
    "#     cross join extra as t2\n",
    "# where\n",
    "#     t1.id <> t2.id\n",
    "# \"\"\"\n",
    "\n",
    "# def nth(it, n):\n",
    "#     for i, e in enumerate(it):\n",
    "#         if i % n == 0:\n",
    "#             yield e\n",
    "\n",
    "# nrows = cur.execute(\"select count(*) from extra as t1 cross join extra as t2 where t1.id <> t2.id\").fetchone()[0]\n",
    "\n",
    "# with ProcessPoolExecutor(max_workers = 22, initializer = init_worker, initargs = (ngram_similarity.NgramSimilarity(\"en\"), modified_ngram_similarity.ModifiedNgramSimilarity(\"en\"))) as executor:\n",
    "#     for batch in chunk(24, chunk(10, nth(cur.execute(sql_extra_gt).fetchall(), int(nrows/12000)))):\n",
    "#         jobs = []\n",
    "\n",
    "#         for workbundle in batch:\n",
    "#             rows = []\n",
    "#             for ida, idb in workbundle:\n",
    "#                 texta = cur.execute(f\"select text from extra where id={ida}\").fetchone()[0]\n",
    "#                 textb = cur.execute(f\"select text from extra where id={idb}\").fetchone()[0]\n",
    "#                 if not len(texta) > 50_000 and not len(textb) > 50_000:\n",
    "#                     rows.append((ida, idb, texta, textb))\n",
    "\n",
    "#             if rows:\n",
    "#                 job = executor.submit(score_rows, rows)\n",
    "#                 jobs.append(job)\n",
    "\n",
    "#         bundleresults = [f.result() for f in as_completed(jobs)]\n",
    "#         for results in bundleresults:\n",
    "#             for (ida, idb), scores in results.items():\n",
    "#                 cur.execute(\n",
    "#                     \"INSERT OR IGNORE INTO extra_predictions VALUES (?, ?, ?, ?)\",\n",
    "#                     (\n",
    "#                         ida,\n",
    "#                         idb,\n",
    "#                         json.dumps(scores, ensure_ascii=False),\n",
    "#                         None\n",
    "#                     )\n",
    "#                 )\n",
    "#         con.commit()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "con.close()\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}